name: run crawler

on:
  workflow_call:
    inputs:
      command:
        required: true
        type: string
      data-repository:
        required: true
        type: string
    secrets:
      ATCODER_SESSION:
        required: true
      HEALTHCHECK_UUID:
        required: true
      DATA_DEPLOY_KEY:
        required: true

jobs:
  run-crawler:
    runs-on: ubuntu-latest
    env:
      REPOSITORY_PATH: ./ac-predictor-data # TODO: make absolute paths
    steps:
      - name: Setup deploy key
        run: |
          mkdir -p ~/.ssh
          echo '${{ secrets.DATA_DEPLOY_KEY }}' > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key

      - name: Checkout crawler
        uses: actions/checkout@v4
        with:
          path: ac-predictor

      - name: Checkout data
        uses: actions/checkout@v4
        with:
            repository: ${{ inputs.data-repository }}
            path: ac-predictor-data
            ssh-key: ${{ secrets.DATA_DEPLOY_KEY }}

      - name: Install Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install crawler
        run: |
          pip install -e ac-predictor/crawler

      - name: Setup crawler
        run: |
          git config --global user.name ac-predictor
          git config --global user.email kymn0116+ac-predictor@gmail.com
          ac-predictor-crawler login --session '${{ secrets.ATCODER_SESSION }}'

      - name: Run crawler
        run: |
          ${{ inputs.command }}
          curl -fsS -m 10 --retry 5 https://hc-ping.com/${{ secrets.HEALTHCHECK_UUID }}/$?
